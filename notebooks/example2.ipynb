{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca9481ad",
   "metadata": {},
   "source": [
    "# Learn-to-Rank Keras Example with txt files\n",
    "\n",
    "https://github.com/tensorflow/ranking/blob/master/tensorflow_ranking/examples/keras/keras_dnn_tfrecord.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b27bb19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_ranking as tfr\n",
    "import glob\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b28a6e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24be00e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.0.dev'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfr.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc58b837",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/data/example.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "033689ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"1 qid:10 32:0.14 48:0.97 51:0.45\n",
    "0 qid:10 1:0.15 31:0.75 32:0.24 49:0.6\n",
    "2 qid:10 1:0.71 2:0.36 31:0.58 51:0.12\n",
    "0 qid:20 4:0.79 31:0.01 33:0.05 35:0.27\n",
    "3 qid:20 1:0.42 28:0.79 35:0.30 42:0.76\"\"\"\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a36598f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 qid:10 32:0.14 48:0.97 51:0.45\r\n",
      "0 qid:10 1:0.15 31:0.75 32:0.24 49:0.6\r\n",
      "2 qid:10 1:0.71 2:0.36 31:0.58 51:0.12\r\n",
      "0 qid:20 4:0.79 31:0.01 33:0.05 35:0.27\r\n",
      "3 qid:20 1:0.42 28:0.79 35:0.30 42:0.76"
     ]
    }
   ],
   "source": [
    "!cat \"$filename\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b421b052",
   "metadata": {},
   "source": [
    "### Keras example\n",
    "\n",
    "https://github.com/tensorflow/ranking/blob/master/tensorflow_ranking/examples/keras/keras_dnn_tfrecord.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "360a3305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "from absl import app\n",
    "from absl import flags\n",
    "import tensorflow as tf\n",
    "import tensorflow_ranking as tfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "696c2b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "num_features = 136\n",
    "\n",
    "# The document relevance label.\n",
    "_LABEL_FEATURE = \"utility\"\n",
    "\n",
    "# Padding labels are set negative so that the corresponding examples can be\n",
    "# ignored in loss and metrics.\n",
    "_PADDING_LABEL = -1\n",
    "_MASK = \"example_list_mask\"\n",
    "\n",
    "def _create_feature_spec() -> Tuple[Dict[str, tf.io.FixedLenFeature], Dict[\n",
    "    str, tf.io.FixedLenFeature], Tuple[str, tf.io.FixedLenFeature]]:\n",
    "    \"\"\"Create context and example feature spec for data parsing.\n",
    "    Returns:\n",
    "    (context feature specs, example feature specs, label spec).\n",
    "    \"\"\"\n",
    "    context_feature_spec = {}\n",
    "    example_feature_spec = {\n",
    "      \"custom_features_{}\".format(i + 1):\n",
    "      tf.io.FixedLenFeature(shape=(1,), dtype=tf.float32, default_value=0.0)\n",
    "      for i in range(0, num_features)\n",
    "    }\n",
    "    label_spec = (_LABEL_FEATURE,\n",
    "                tf.io.FixedLenFeature(\n",
    "                    shape=(1,), dtype=tf.int64, default_value=_PADDING_LABEL))\n",
    "    return context_feature_spec, example_feature_spec, label_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2f5f803",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "context_feature_spec, example_feature_spec, label_spec = _create_feature_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65b99e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_feature_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e62a5bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_feature_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a16cbe8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FixedLenFeature(shape=(1,), dtype=tf.float32, default_value=0.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_feature_spec['custom_features_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a9811b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('utility', FixedLenFeature(shape=(1,), dtype=tf.int64, default_value=-1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae925ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_ranking.python.keras.pipeline import DatasetHparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a433dce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_len = 51\n",
    "\n",
    "def parsing():\n",
    "\n",
    "    def convert(line):\n",
    "        \n",
    "        columns = tf.strings.split([line], ' ')\n",
    "        labels = tf.strings.to_number(columns.values[0], out_type=tf.int32)\n",
    "        labels = tf.reshape(labels, [-1])\n",
    "        splits = tf.strings.split(columns.values[2:], ':') # skip qid:<number>\n",
    "        id_vals = tf.reshape(splits.values, (splits.shape[0], 2))\n",
    "        feat_ids, feat_vals = tf.split(id_vals, num_or_size_splits=2, axis=1)\n",
    "        feat_ids = tf.strings.to_number(feat_ids, out_type=tf.int64)\n",
    "        feat_vals = tf.strings.to_number(feat_vals, out_type=tf.float32)\n",
    "        sparse_feature = tf.SparseTensor(feat_ids-1, tf.reshape(feat_vals, [-1]), [feature_len])\n",
    "        dense_feature = tf.sparse.to_dense(sparse_feature)\n",
    "        return dense_feature, labels\n",
    "\n",
    "    return convert\n",
    "\n",
    "\n",
    "def get_dataset(filenames):\n",
    "    \"\"\" Read dataset from filenames \"\"\"\n",
    "\n",
    "    dataset = tf.data.TextLineDataset(filenames)\n",
    "    dataset = dataset.map(tf.strings.strip).filter(lambda line: tf.strings.length(line) > 0)\n",
    "\n",
    "    # tf.py_function to be used as contents could not be read directly with map and the function as argument\n",
    "    dataset = dataset.map(\n",
    "        lambda data: tf.py_function(\n",
    "            parsing(),\n",
    "            [ data ],\n",
    "            (tf.float32, tf.int32),\n",
    "            name=\"features_labels_parser\")\n",
    "    )\n",
    "    \n",
    "    # Shape is lost after py_function: https://github.com/tensorflow/tensorflow/issues/31373\n",
    "    # Shape cannot be inferred: https://github.com/tensorflow/tensorflow/issues/16052\n",
    "    dataset = dataset.map(\n",
    "        lambda x, y: (tf.reshape(x, (51,), name=None), \n",
    "                      tf.reshape(y, (1,), name=None)))\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1dd01c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "train_input_pattern = \"/data/example.txt\"\n",
    "valid_input_pattern = \"/data/example.txt\"\n",
    "train_batch_size = 1\n",
    "valid_batch_size = 1\n",
    "list_size = None\n",
    "convert_labels_to_binary = False\n",
    "\n",
    "# Get dataset hyperparams\n",
    "dataset_hparams = tfr.python.keras.pipeline.DatasetHparams(\n",
    "    train_input_pattern=train_input_pattern,\n",
    "    valid_input_pattern=valid_input_pattern,\n",
    "    train_batch_size=train_batch_size,\n",
    "    valid_batch_size=valid_batch_size,\n",
    "    list_size=list_size,\n",
    "    dataset_reader=get_dataset,\n",
    "    convert_labels_to_binary=convert_labels_to_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c92f5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetHparams(train_input_pattern='/data/example.txt', valid_input_pattern='/data/example.txt', train_batch_size=1, valid_batch_size=1, list_size=None, valid_list_size=None, dataset_reader=<function get_dataset at 0x7f56ffe8adc0>, convert_labels_to_binary=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ae92c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_hparams.valid_list_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6d0d820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.get_dataset(filenames)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_hparams.dataset_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eac17788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((51,), (1,)), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_hparams.dataset_reader([ filename ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea64fa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(dataset_hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9963040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "model_dir = f\"/tmp/tf-ranking-{datetime.now().strftime('%d-%m-%Y-%H-%M-%S')}\"\n",
    "num_epochs = 10\n",
    "num_train_steps = 1000\n",
    "num_valid_steps = 100\n",
    "loss = \"approx_ndcg_loss\"\n",
    "optimizer = \"adagrad\"\n",
    "learning_rate = 0.005\n",
    "steps_per_execution = 10\n",
    "export_best_model = False\n",
    "strategy = \"MirroredStrategy\"\n",
    "\n",
    "pipeline_hparams = tfr.keras.pipeline.PipelineHparams(\n",
    "      model_dir=model_dir,\n",
    "      num_epochs=num_epochs,\n",
    "      steps_per_epoch=(num_train_steps // num_epochs),\n",
    "      validation_steps=num_valid_steps,\n",
    "      loss=loss,\n",
    "      loss_reduction=tf.losses.Reduction.AUTO,\n",
    "      optimizer=optimizer,\n",
    "      learning_rate=learning_rate,\n",
    "      steps_per_execution=steps_per_execution,\n",
    "      export_best_model=export_best_model,\n",
    "      strategy=strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26a08378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineHparams(model_dir='/tmp/tf-ranking-22-06-2021-15-11-58', num_epochs=10, steps_per_epoch=100, validation_steps=100, learning_rate=0.005, loss='approx_ndcg_loss', loss_reduction='auto', optimizer='adagrad', loss_weights=None, steps_per_execution=10, automatic_reduce_lr=False, use_weighted_metrics=False, export_best_model=False, best_exporter_metric_higher_better=False, best_exporter_metric='loss', strategy='MirroredStrategy', tpu='')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73b27df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "use_log1p = False\n",
    "\n",
    "preprocess_dict = {}\n",
    "if use_log1p:\n",
    "    preprocess_dict = {\n",
    "        fname: lambda t: tf.math.log1p(t * tf.sign(t)) * tf.sign(t)\n",
    "        for fname in example_feature_spec.keys()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78d7f35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_dims = \"64,32,16\"\n",
    "use_batch_norm = True\n",
    "batch_norm_moment = 0.99\n",
    "dropout = 0.4\n",
    "\n",
    "dnn_scorer = tfr.keras.model.DNNScorer(\n",
    "    hidden_layer_dims=map(int, hidden_layer_dims.split(\",\")),\n",
    "    output_units=1,\n",
    "    activation=tf.nn.relu,\n",
    "    input_batch_norm=use_batch_norm,\n",
    "    use_batch_norm=use_batch_norm,\n",
    "    batch_norm_moment=batch_norm_moment,\n",
    "    dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7203596a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_ranking.python.keras.model.DNNScorer at 0x7f56ffe6ecd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa94990d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder = tfr.keras.model.ModelBuilder(\n",
    "    input_creator=tfr.keras.model.FeatureSpecInputCreator(\n",
    "      context_feature_spec, \n",
    "        example_feature_spec),\n",
    "    preprocessor=tfr.keras.model.PreprocessorWithSpec(preprocess_dict),\n",
    "    scorer=dnn_scorer,\n",
    "    mask_feature_name=_MASK,\n",
    "    name=\"keras_dnn_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d9ccb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_ranking.python.keras.model.ModelBuilder at 0x7f56ffe6e5b0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5621ebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(model_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b76c451e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "ranking_pipeline = tfr.keras.pipeline.SimplePipeline(\n",
    "    model_builder=model_builder,\n",
    "    dataset_builder=tfr.keras.pipeline.SimpleDatasetBuilder(\n",
    "        context_feature_spec=context_feature_spec,\n",
    "        example_feature_spec=example_feature_spec,\n",
    "        mask_feature_name=_MASK,\n",
    "        label_spec=label_spec,\n",
    "        hparams=dataset_hparams),\n",
    "    hparams=pipeline_hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f042ea16",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n\n    TypeError: tf__parse_from_example_list() got multiple values for argument 'list_size'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-7026184516c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mranking_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow_ranking/python/keras/pipeline.py\u001b[0m in \u001b[0;36mtrain_and_validate\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    593\u001b[0m       \u001b[0;31m# Otherwise, MultiWorkerMirroredStrategy will fail.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m       train_dataset, valid_dataset = (\n\u001b[0;32m--> 595\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_builder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_train_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m           self._dataset_builder.build_valid_dataset())\n\u001b[1;32m    597\u001b[0m       model.fit(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow_ranking/python/keras/pipeline.py\u001b[0m in \u001b[0;36mbuild_train_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    961\u001b[0m     \u001b[0;34m\"\"\"See `AbstractDatasetBuilder`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0mtrain_list_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m     return self._build_dataset(\n\u001b[0m\u001b[1;32m    964\u001b[0m         \u001b[0mfile_pattern\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_input_pattern\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow_ranking/python/keras/pipeline.py\u001b[0m in \u001b[0;36m_build_dataset\u001b[0;34m(self, file_pattern, batch_size, list_size, randomize_input, num_epochs)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \"\"\"\n\u001b[1;32m    931\u001b[0m     \u001b[0;31m# TODO: Remove defaults common in Estimator pipeline and here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m     dataset = data.build_ranking_dataset(\n\u001b[0m\u001b[1;32m    933\u001b[0m         \u001b[0mfile_pattern\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_pattern\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mELWC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow_ranking/python/data.py\u001b[0m in \u001b[0;36mbuild_ranking_dataset\u001b[0;34m(file_pattern, data_format, batch_size, context_feature_spec, example_feature_spec, list_size, size_feature_name, mask_feature_name, shuffle_examples, seed, **kwargs)\u001b[0m\n\u001b[1;32m   1013\u001b[0m       seed=seed)\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m   return build_ranking_dataset_with_parsing_fn(\n\u001b[0m\u001b[1;32m   1016\u001b[0m       file_pattern, parsing_fn=parsing_fn, batch_size=batch_size, **kwargs)\n\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow_ranking/python/data.py\u001b[0m in \u001b[0;36mbuild_ranking_dataset_with_parsing_fn\u001b[0;34m(file_pattern, parsing_fn, batch_size, reader, reader_args, num_epochs, shuffle, shuffle_buffer_size, shuffle_seed, prefetch_buffer_size, reader_num_threads, sloppy_ordering, drop_final_batch, num_parser_threads)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m   \u001b[0;31m# Parse a batch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m   \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsing_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_parser_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m   \u001b[0;31m# Prefetching allows for data fetching to happen on host while model runs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1925\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1927\u001b[0;31m       return ParallelMapDataset(\n\u001b[0m\u001b[1;32m   1928\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1929\u001b[0m           \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4520\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4521\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4522\u001b[0;31m     self._map_func = StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m   4523\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4524\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3710\u001b[0m     \u001b[0mresource_tracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceTracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3711\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3712\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3713\u001b[0m       \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3714\u001b[0m       \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3132\u001b[0m          \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m     \"\"\"\n\u001b[0;32m-> 3134\u001b[0;31m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[1;32m   3135\u001b[0m         *args, **kwargs)\n\u001b[1;32m   3136\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3098\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3099\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3100\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3101\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3102\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3279\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3685\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3686\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3687\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3688\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3689\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3615\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3616\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3617\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3618\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3619\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n\n    TypeError: tf__parse_from_example_list() got multiple values for argument 'list_size'\n"
     ]
    }
   ],
   "source": [
    "ranking_pipeline.train_and_validate(verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6a15dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
